{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Institute of Coding](assets/header.png)\n",
    "\n",
    "\n",
    "\n",
    "![Cover image for Face recognition with scikit-learn (sklearn) SVM ](assets/svm-header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face recognition, or facial recognition, is one of the most common artificial intelligence and machine learning application across all sectors. The problem has been around for nearly half a century. We will cover the most basic face recognition application using support vector machines (SVM) of the scikit-learn (sklearn) library.\n",
    "\n",
    "For training and testing of the face recognition model, we will use the olivetti face dataset which collected in AT&T Laboratories Cambridge, between 1992 and 1994. Olivetti face dataset contains 400 face images of 40 people, 10 face images each, in grayscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and loading dataset\n",
    "\n",
    "Luckily, scikit-learn provides utilities for downloading and loading olivetti face dataset. We can load the dataset with a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the dataset's contents for easier and more convenient access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dataset for easy access\n",
    "X = data[\"data\"]\n",
    "imgs = data[\"images\"]\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview of the Dataset\n",
    "\n",
    "Before directly diving into classification, let's see a preview of the dataset. To do that, we'll plot first face image of every person, 40 faces in total using the matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from math import ceil\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# select unique people ids\n",
    "people_ids = set(y)\n",
    "\n",
    "# setting layout for subplots.\n",
    "n_cols = 8\n",
    "n_rows = ceil(len(people_ids) / n_cols)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(16, 10))\n",
    "\n",
    "# iterate over the ids of people and plot first image for each of them\n",
    "for person_id in people_ids:\n",
    "    # finding indexes of the person_id\n",
    "    person_ixs = y == person_id\n",
    "    # selecting the images of the person and picking the first one for preview\n",
    "    image = data[\"images\"][person_ixs][0]\n",
    "    # plotting the image as grayscale\n",
    "    axes[person_id // n_cols][person_id % n_cols].imshow(image, cmap=\"gray\")\n",
    "    # setting subplot title\n",
    "    title = \"Person: {:02d}\".format(person_id)\n",
    "    axes[person_id // n_cols][person_id % n_cols].set_title(title)\n",
    "\n",
    "# removing ticks on x & y axis\n",
    "plt.setp(axes, xticks=[], yticks=[])\n",
    "\n",
    "# setting general plot title\n",
    "plt.suptitle(\"AT&T Laboratories Cambridge ’92-’94 - Olivetti Face Dataset\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will approach face recognition problem as a classification problem where subject (person) ids are the classes, and face images are the samples. Trying to identify person id from a face image will be a classical classification problem. \n",
    "\n",
    "Although, a preprocessing operation over the data is needed for most machine learning problems, the olivetti dataset has been already preprocessed, therefore we don't need to do anything. The landmarks of the faces of all subjects are aligned to the same position, the colors are mapped to 256 shades of grey with no hair and background for every image in the dataset.\n",
    "\n",
    "Yet, we still need to split the data into train and test split, so that we can measure the performance of our SVM model. In order to split face images equally, we'll use `StratifiedShuffleSplit` class of sklearn which enables us to create randomized train and test sets for a cross validation with equal train/test ratio for all classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# split data randomly into train & test sets by preserving train/test ratio across classes\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "# get the train and test indexes\n",
    "train_index, test_index = next(sss.split(X, y))\n",
    "\n",
    "# split X and y into train & test sets\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# Print statistics about it\n",
    "print(f\"Train data size: {len(y_train)}\")\n",
    "print(f\"Test data size : {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, we split train & test sets using %80 and %20 of the data, respectively. We can access training data as `X_train`, test data as `X_test`, train labels are `y_train`, and test labels as `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Since we have all the the data we need, we can go into classification phase. Scikit-learn provides many classification methods in a general classification interface. We will use Support Vector Machines (SVM) classifier among all classifiers scikit provides.\n",
    "\n",
    "First define the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import timeit\n",
    "\n",
    "# define the SVM classifier with a Radial Basis Function (RBF) kernel.\n",
    "classifier = SVC(kernel=\"rbf\", gamma=\"scale\", random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using training data and labels, train the classifier model using the `fit` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier and keep track of the time for training.\n",
    "time = timeit.timeit(lambda: classifier.fit(X_train, y_train), number=1)\n",
    "print(f\"Training completed in {time:.2f} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have completed training of the classifier, let's see what it predicts when we try to classify our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the performance of the classifier, we can use `accuracy_score` metric of the scikit-learn library. Accuracy score is the percentage of correctly predicted samples among all test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {100 * accuracy:.2f}%\")\n",
    "\n",
    "num_correct = np.sum(y_test == y_pred)\n",
    "print(f\"Number of correctly classified samples: {num_correct}\")\n",
    "\n",
    "num_incorrect = len(y_test) - num_correct\n",
    "print(f\"Number of incorrectly classified samples: {num_incorrect}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a couple of lines, we have successfully created a face recognition model which works quite good! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
